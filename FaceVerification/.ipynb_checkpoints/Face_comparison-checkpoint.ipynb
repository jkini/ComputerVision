{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2 as ocr\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import shutil\n",
    "from tqdm import tqdm,trange\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "from numpy.random import choice\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation,BatchNormalization,Lambda, Input, Conv2D, Dense,MaxPooling2D, Dropout, Flatten, UpSampling2D, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNextbatch(batch_size=10, stepNumber=0, imgDim = 128, imageFiles = 'list/of/files', pathSplitIndex = 2, classValLength = 4):\n",
    "    import cv2 as ocr\n",
    "    try:\n",
    "        input_label_list = []\n",
    "        input_data_list = []\n",
    "        counter = 0\n",
    "        start = stepNumber\n",
    "        end = stepNumber + batch_size\n",
    "\n",
    "        for imgF in imageFiles[start:end]:\n",
    "          \n",
    "            input_label_list.append(int(imgF.split('/')[pathSplitIndex][0:classValLength]))\n",
    "            input_data_list.append(ocr.imread(imgF,0))\n",
    "\n",
    "        return (np.array(input_data_list).reshape(-1,imgDim,imgDim,1)\n",
    "                , np.array(input_label_list).astype('int64'))\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        \n",
    "def getData(dataPath='path/To/Data',channels = 0, pathSplitIndex = 2, classValLength = 4, classCount = None, classValue = None):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    imageClass = []\n",
    "    imageFiles = [] \n",
    "    input_label_list = []\n",
    "    input_data_list = []   \n",
    "    selectedFilePaths = []\n",
    "    imageFiles = [dataPath+'/'+f for f in listdir(dataPath) if isfile(join(dataPath, f))]\n",
    "    \n",
    "    for imgF in tqdm(imageFiles, total=len(imageFiles), unit=\"files\"): \n",
    "#         print(imgF)\n",
    "        c = int(imgF.split('/')[pathSplitIndex][0:classValLength])\n",
    "        if( classCount!=None and classValue == None):\n",
    "            imageClass.append(c) \n",
    "            if(len(Counter(imageClass).keys())>classCount):\n",
    "                imageClass[classCount] = imageClass[classCount-1]\n",
    "            else:\n",
    "#                 input_label_list.append(c)\n",
    "#                 input_data_list.append(ocr.imread(imgF,channels))\n",
    "                selectedFilePaths.append(imgF)\n",
    "        elif(classCount==None and classValue!=None):\n",
    "            if(c in classValue):\n",
    "#                 input_label_list.append(c)\n",
    "#                 input_data_list.append(ocr.imread(imgF,channels))\n",
    "                selectedFilePaths.append(imgF)\n",
    "        imageClass = list(set(imageClass))\n",
    "    return np.array(selectedFilePaths)\n",
    "\n",
    "def contrastive_loss(left_model, right_model, y, margin):\n",
    "    with tf.name_scope(\"contrastive-loss\"):\n",
    "        d = tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(left_model,right_model), 2), 1, keep_dims=True))\n",
    "        part1= y * tf.square(d)    \n",
    "        part2 = (1 - y) * tf.square(tf.maximum((margin - d),0))\n",
    "        return tf.reduce_mean(part1 + part2) /2\n",
    "    \n",
    "\n",
    "images_folder_tr = 'images-32-lfw/'\n",
    "images_folder_val = images_folder_tr\n",
    "def gen_random_train_batch(nb_examples):\n",
    "    out_l,out_r,out_y = [],[],[]\n",
    "    li = random.sample(range(len(df_train)), nb_examples)\n",
    "    for i in li:\n",
    "        im_l = df_train.iloc[i]['name1']+\"/\"+df_train.iloc[i]['name1']+'_'+str(df_train.iloc[i]['im1']).zfill(4)+\".jpg\"\n",
    "        im_r = df_train.iloc[i]['name2']+\"/\"+df_train.iloc[i]['name2']+'_'+str(df_train.iloc[i]['im2']).zfill(4)+\".jpg\"\n",
    "        \n",
    "        \n",
    "        out_l.append(ocr.imread(images_folder_tr+im_l,0))\n",
    "        out_r.append(ocr.imread(images_folder_tr+im_r,0))\n",
    "        out_y.append(df_train.iloc[i]['label'])\n",
    "    out_l = ((np.array(out_l))/255.0).astype('float32')\n",
    "    out_r = ((np.array(out_r))/255.0).astype('float32')\n",
    "    out_y = np.array(out_y).reshape((-1,1))\n",
    "    return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1), np.array(out_y)\n",
    "\n",
    "def gen_random_val_batch(nb_examples):\n",
    "    out_l,out_r,out_y = [],[],[]\n",
    "    li = random.sample(range(len(df_val)), nb_examples)\n",
    "    for i in li:\n",
    "        \n",
    "        im_l = df_val.iloc[i]['name1']+\"/\"+df_val.iloc[i]['name1']+'_'+str(df_val.iloc[i]['im1']).zfill(4)+\".jpg\"\n",
    "        im_r = df_val.iloc[i]['name2']+\"/\"+df_val.iloc[i]['name2']+'_'+str(df_val.iloc[i]['im2']).zfill(4)+\".jpg\"\n",
    "        \n",
    "        \n",
    "        out_l.append(ocr.imread(images_folder_val+im_l,0))\n",
    "        out_r.append(ocr.imread(images_folder_val+im_r,0))\n",
    "        out_y.append(df_val.iloc[i]['label'])\n",
    "    out_l = ((np.array(out_l))/255.0).astype('float32')\n",
    "    out_r = ((np.array(out_r))/255.0).astype('float32')\n",
    "    out_y = np.array(out_y).reshape((-1,1))\n",
    "    return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1), np.array(out_y)\n",
    "\n",
    "# def gen_random_train_batch_sift(nb_examples):\n",
    "#     out_l,out_r,sift_l,sift_r,out_y = [],[],[],[],[]\n",
    "#     li = random.sample(range(len(df_train)), nb_examples)\n",
    "#     for i in li:\n",
    "#         out_l.append(ocr.imread(images_folder_tr+df_train.iloc[i]['left'],0))\n",
    "#         out_r.append(ocr.imread(images_folder_tr+df_train.iloc[i]['right'],0))\n",
    "#         sift_l.append(df_train.iloc[i][3:259])\n",
    "#         sift_r.append(df_train.iloc[i][259:])\n",
    "#         out_y.append(df_train.iloc[i]['label'])\n",
    "#     out_l = ((255.01 - np.array(out_l))/255.0).astype('float32')\n",
    "#     out_r = ((255.01 - np.array(out_r))/255.0).astype('float32')\n",
    "#     sift_l = np.array(sift_l).reshape((-1,256))\n",
    "#     sift_r = np.array(sift_r).reshape((-1,256))\n",
    "#     out_y = np.array(out_y).reshape((-1,1))\n",
    "#     return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1),sift_l,sift_r, out_y\n",
    "\n",
    "# def gen_random_val_batch_sift(nb_examples):\n",
    "#     out_l,out_r,sift_l,sift_r,out_y = [],[],[],[],[]\n",
    "#     li = random.sample(range(len(df_val)), nb_examples)\n",
    "#     for i in li:\n",
    "#         out_l.append(ocr.imread(images_folder_val+df_val.iloc[i]['left'],0))\n",
    "#         out_r.append(ocr.imread(images_folder_val+df_val.iloc[i]['right'],0))\n",
    "#         sift_l.append(df_val.iloc[i][3:259])\n",
    "#         sift_r.append(df_val.iloc[i][259:])\n",
    "#         out_y.append(df_val.iloc[i]['label'])\n",
    "#     out_l = ((255.01 - np.array(out_l))/255.0).astype('float32')\n",
    "#     out_r = ((255.01 - np.array(out_r))/255.0).astype('float32')\n",
    "#     sift_l = np.array(sift_l).reshape((-1,256))\n",
    "#     sift_r = np.array(sift_r).reshape((-1,256))\n",
    "#     out_y = np.array(out_y).reshape((-1,1))\n",
    "#     return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1),sift_l,sift_r, out_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "# def generateDatasetAndSave_Siamese():\n",
    "#     label = []\n",
    "#     left_path = []\n",
    "#     right_path = []\n",
    "#     simCounter = 0\n",
    "#     for l,r in combinations(train_files_list,2):\n",
    "#         if(int(l.split('/')[3][:4]) == int(r.split('/')[3][:4])):\n",
    "#             label.append([1])\n",
    "#     #     else:\n",
    "#     #         label.append([0,1])\n",
    "#             left_path.append(l)\n",
    "#             right_path.append(r)\n",
    "#             simCounter+=1\n",
    "#     diffCounter = 0\n",
    "#     for l,r in combinations(train_files_list,2):\n",
    "#         if(int(l.split('/')[3][:4]) != int(r.split('/')[3][:4])):\n",
    "#             label.append([0])\n",
    "#     #     else:\n",
    "#     #         label.append([0,1])\n",
    "#             left_path.append(l)\n",
    "#             right_path.append(r)\n",
    "#             diffCounter+=1\n",
    "#         if(diffCounter==simCounter):\n",
    "#             break\n",
    "#     df = pd.DataFrame()\n",
    "#     pd.options.display.max_colwidth = 100\n",
    "#     df['left'] = left_path\n",
    "#     df['right'] = right_path\n",
    "#     df['label'] = label\n",
    "#     df.to_csv('dataset_training_siamese.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imDim = 32\n",
    "mode = 'concat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature extracter model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 410,816\n",
      "Trainable params: 410,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "input_shape  = (imDim,imDim,1)\n",
    "inp_img = Input(shape = (imDim,imDim,1), name = 'ImageInput')\n",
    "model = inp_img\n",
    "\n",
    "#     model = Input(shape=(imDim,imDim,1))\n",
    "#     model.add(Input(shape = (imDim,imDim,1), name = 'FeatureNet_ImageInput'))\n",
    "model = Conv2D(64,kernel_size=(3, 3),activation='relu',input_shape=input_shape,padding='same')(model)\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model = MaxPooling2D((2,2), padding='valid')(model)\n",
    "model = Conv2D(128, (3, 3), activation='relu',padding='same')(model)\n",
    "#     model.add(Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "model = Dropout(0.3)(model)\n",
    "#     model.add(Conv2D(16, (3, 3), activation='relu',padding='same'))\n",
    "model = Conv2D(256, (3, 3), activation='relu',padding='same')(model)\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "#     model.add(Conv2D(1, (3, 3), activation='relu',padding='same'))\n",
    "#     model.add(Conv2D(2, (3, 3), activation='relu',padding='same'))\n",
    "model = Dropout(0.3)(model)\n",
    "model = Conv2D(128, (1, 1), activation='relu',padding='valid')(model)\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "model = Dropout(0.3)(model)\n",
    "model = Conv2D(64, (1, 1), activation='relu',padding='valid')(model)\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "\n",
    "model = Flatten()(model)\n",
    "\n",
    "# img_in = np.array((-1,imDim,imDim,1), dtype='float32')\n",
    "# img_in = tf.placeholder(shape=(imDim,imDim,1), dtype='float32')\n",
    "\n",
    "feat = Model(inputs=[inp_img], outputs=[model],name = 'Feat_Model')\n",
    "feat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_img = Input(shape = (imDim,imDim,1), name = 'left_img')\n",
    "right_img = Input(shape = (imDim,imDim,1), name = 'right_img')\n",
    "# left_sift = Input(shape= (256,), name = 'left_sift')\n",
    "# right_sift = Input(shape= (256,), name = 'right_sift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Feat_Model/flatten_1/Reshape:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "left_feats = feat(left_img)\n",
    "right_feats = feat(right_img)\n",
    "\n",
    "# inpTensor = Input((1,256,), name = 'SIFTInput')\n",
    "# finalOut = Flatten()(inpTensor)  \n",
    "# sift_model = Model(inputs=[inpTensor], outputs=[finalOut], name='Sift_Model')\n",
    "# sift_model.summary()\n",
    "\n",
    "# left_sift_feats = sift_model(left_sift)\n",
    "# right_sift_feats = sift_model(right_sift)\n",
    "# print(left_sift_feats)\n",
    "print(left_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, subtract, multiply, division\n",
    "from keras.utils import to_categorical\n",
    "import random  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_img (InputLayer)           (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "right_img (InputLayer)          (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Feat_Model (Model)              (None, 64)           410816      left_img[0][0]                   \n",
      "                                                                 right_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merged_feats (Concatenate)      (None, 128)          0           Feat_Model[1][0]                 \n",
      "                                                                 Feat_Model[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         132096      merged_feats[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1024)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            4100        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4)            16          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4)            0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4)            0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            10          dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 551,134\n",
      "Trainable params: 549,078\n",
      "Non-trainable params: 2,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## CNN+SIFT\n",
    "# merged_feats = concatenate([left_feats, right_feats, left_sift_feats, right_sift_feats], name = 'merged_feats')\n",
    "## Only SIFT merge\n",
    "# merged_feats = concatenate([left_sift_feats, right_sift_feats], name = 'merged_feats')\n",
    "## Only CNN merge\n",
    "if mode == 'concat':\n",
    "    merged_feats = concatenate([left_feats, right_feats], name = 'merged_feats')\n",
    "elif mode == 'subtract':\n",
    "    merged_feats = subtract([left_feats, right_feats], name = 'merged_feats')\n",
    "merged_feats = Dense(1024, activation = 'linear')(merged_feats)\n",
    "merged_feats = BatchNormalization()(merged_feats)\n",
    "merged_feats = Activation('relu')(merged_feats)\n",
    "merged_feats = Dropout(0.3)(merged_feats)\n",
    "merged_feats = Dense(4, activation = 'linear')(merged_feats)\n",
    "merged_feats = BatchNormalization()(merged_feats)\n",
    "merged_feats = Activation('relu')(merged_feats)\n",
    "merged_feats = Dropout(0.3)(merged_feats)\n",
    "merged_feats = Dense(2, activation = 'softmax')(merged_feats)\n",
    "## only sift\n",
    "# similarity_model = Model(inputs = [left_sift,right_sift], outputs = [merged_feats], name = 'Similarity_Model')\n",
    "## only cnn\n",
    "similarity_model = Model(inputs = [left_img, right_img], outputs = [merged_feats], name = 'Similarity_Model')\n",
    "## with cnn+sift\n",
    "# similarity_model = Model(inputs = [left_img, right_img, left_sift,right_sift], outputs = [merged_feats], name = 'Similarity_Model')\n",
    "similarity_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_folder = ''\n",
    "sgd = K.optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "similarity_model.compile(optimizer=sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# similarity_model.load_weights('weights/weights-siamese-AND-concat-cnn-0.377613.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = 'pairsDevTrain.csv'\n",
    "val_set = 'pairsDevTest.csv'\n",
    "df_train = pd.DataFrame.from_csv(train_set).reset_index()\n",
    "df_val = pd.DataFrame.from_csv(val_set).reset_index()\n",
    "df_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iteration = 0\n",
    "# left_image = ocr.imread(df.iloc[iteration]['left'],0)\n",
    "# right_image = ocr.imread(df.iloc[iteration]['right'],0)\n",
    "# y = df.iloc[iteration]['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on: 2200, Validate on: 1000\n",
      "Epoch: 1  Train accuracy: 48.4835%, Validation acc: 50.0000%, Tr Loss: 0.814915 (improved)\n",
      "Epoch: 2  Train accuracy: 49.2877%, Validation acc: 50.0000%, Tr Loss: 0.805256 (improved)\n",
      "Training the model: 28/34 (82.4%)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d5093250d162>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_files_list\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mleft_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_random_train_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#         print('\\n------\\n'+str(y)+'\\n------\\n')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e79420f1a987>\u001b[0m in \u001b[0;36mgen_random_train_batch\u001b[1;34m(nb_examples)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mout_l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_folder_tr\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mim_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mout_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_folder_tr\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mim_r\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mout_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "imgDim =  imDim\n",
    "best_loss_tr = np.infty\n",
    "max_val_acc = 0\n",
    "train_files_list = df_train.shape[0]\n",
    "train_num_examples = train_files_list\n",
    "print('Train on: %2d, Validate on: %2d' %(train_num_examples, df_val.shape[0]))\n",
    "n_iterations_per_epoch = train_num_examples // batch_size\n",
    "# n_iterations_validation = val_num_examples // batch_size\n",
    "# Set's how much noise we're adding to the MNIST images\n",
    "noise_factor = 0.0\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tr_loss_vals = []\n",
    "tr_acc_vals = []\n",
    "val_acc_vals = []\n",
    "v_batch_size = df_val.shape[0]\n",
    "early_stopping_counter = 0\n",
    "patience = 20\n",
    "\n",
    "\n",
    "batch_metrics = None\n",
    "batch_metric_loss = []\n",
    "batch_metric_acc = []\n",
    "for epoch in range(n_epochs):\n",
    "    for iteration in range(int(train_files_list/batch_size)):        \n",
    "        left_image, right_image, y = gen_random_train_batch(batch_size)\n",
    "        y = to_categorical(y)\n",
    "#         print('\\n------\\n'+str(y)+'\\n------\\n')\n",
    "        left_image = left_image.reshape((-1, imgDim, imgDim, 1))\n",
    "        right_image = right_image.reshape((-1, imgDim, imgDim, 1))\n",
    "#         batch_metrics = similarity_model.train_on_batch([left_image,right_image,sift_l,sift_r],[y])\n",
    "#         batch_metrics = similarity_model.train_on_batch([sift_l,sift_r],[y])\n",
    "        batch_metrics = similarity_model.train_on_batch([left_image,right_image],[y])\n",
    "        \n",
    "        batch_metric_loss.append(batch_metrics[0])\n",
    "        batch_metric_acc.append(batch_metrics[1])\n",
    "        print(\"\\rTraining the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_per_epoch,\n",
    "                  iteration * 100 / n_iterations_per_epoch),\n",
    "              end=\"\" * 10)\n",
    "    loss_tr = np.mean(batch_metric_loss)\n",
    "    acc_tr = np.mean(batch_metric_acc)\n",
    "    tr_loss_vals.append(loss_tr)\n",
    "    tr_acc_vals.append(acc_tr)\n",
    "    \n",
    "    v_left_image ,v_right_image, v_y = gen_random_val_batch(v_batch_size)\n",
    "    \n",
    "#     pred_sim = similarity_model.predict([v_left_image ,v_right_image,v_sift_l, v_sift_r])\n",
    "#     pred_sim = similarity_model.predict([v_sift_l, v_sift_r])\n",
    "    pred_sim = similarity_model.predict([v_left_image ,v_right_image])\n",
    "    pred_val_sim = []\n",
    "    for p in pred_sim:\n",
    "        pred_val_sim.append(np.argmax(p))\n",
    "    v_acc = float((np.array(pred_val_sim).reshape((v_batch_size,1))==v_y).sum())/float(len(v_y))\n",
    "    val_acc_vals.append(v_acc)\n",
    "    \n",
    "    print(\"\\rEpoch: {}  Train accuracy: {:.4f}%, Tr Loss: {:.6f}, Validation acc: {:.4f}% {}\".format(\n",
    "        epoch + 1,\n",
    "        (acc_tr) * 100,\n",
    "        (v_acc)*100.0, loss_tr,\n",
    "        \" (improved)\" if v_acc > max_val_acc else \"\"))\n",
    "    if loss_tr < best_loss_tr:\n",
    "        best_loss_tr = loss_tr        \n",
    "    if max_val_acc < v_acc:\n",
    "        max_val_acc = v_acc\n",
    "        early_stopping_counter = 0\n",
    "        filepath='weights/siam-'+str(imgDim)+'-cnn-'+mode+'-[val-acc-'+str(v_acc)+'].hdf5'\n",
    "        similarity_model.save(filepath)\n",
    "    else:\n",
    "        early_stopping_counter+=1\n",
    "    if early_stopping_counter==patience:\n",
    "        print('early stopped - no increase in val acc over previous '+str(patience)+' epochs')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame()\n",
    "df_metrics['accuracy'] = tr_acc_vals\n",
    "df_metrics['loss'] = tr_loss_vals\n",
    "df_metrics['val_acc'] = val_acc_vals\n",
    "df_metrics.to_csv('plots/siam-'+str(imgDim)+'-cnn-'+mode+'-metric-cnn.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = df_metrics.plot()\n",
    "fig = ax.figure\n",
    "fig.savefig('plots/siam-'+str(imgDim)+'-cnn-'+mode+'-plot-cnn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# similarity_model = load model (best one)\n",
    "%matplotlib inline\n",
    "def show_model_output(nb_examples = 5):\n",
    "    \n",
    "#     pv_a, pv_b,pv_s_l,pv_s_r, pv_sim = gen_random_val_batch(nb_examples)\n",
    "    pv_a, pv_b, pv_sim = gen_random_val_batch(nb_examples)\n",
    "#     pred_sim = similarity_model.predict([pv_a, pv_b,pv_s_l,pv_s_r])\n",
    "    pred_sim = similarity_model.predict([pv_a, pv_b])\n",
    "    p_val_argmax=[]\n",
    "    print(pred_sim)\n",
    "    for p in pred_sim:\n",
    "        p_val_argmax.append(np.argmax(p))\n",
    "    p_val_argmax = np.array(p_val_argmax)\n",
    "    fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))\n",
    "    for c_a, c_b, c_d, p_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, pred_sim, m_axs.T):\n",
    "        ax1.imshow(c_a[:,:,0])\n",
    "        ax1.set_title('Left Image\\n Actual Label: %3.0f%%' % (100*c_d))\n",
    "        ax1.axis('off')\n",
    "        ax2.imshow(c_b[:,:,0])\n",
    "        ax2.set_title('Right Image\\n Different %3.0f%% \\nSame %3.0f%% ' % (100*p_d[0],100*p_d[1]))\n",
    "        ax2.axis('off')\n",
    "    return fig\n",
    "# a completely untrained model\n",
    "_ = show_model_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_left_image ,v_right_image, v_y = gen_random_val_batch(100)\n",
    "pred_sim = similarity_model.predict([v_left_image ,v_right_image])\n",
    "(pred_sim.round().astype('int')==v_y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l,r,y = gen_random_train_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.sample(range(1, 10), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(feat, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(similarity_model, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,1,1,1,1,1,1,1,0])\n",
    "b = np.array([1,1,1,1,1,1,1,1,0,0])\n",
    "(a==b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l,r,s,y = gen_random_val_batch_sift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
