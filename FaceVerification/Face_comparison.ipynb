{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2 as ocr\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import shutil\n",
    "from tqdm import tqdm,trange\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "from numpy.random import choice\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation,BatchNormalization,Lambda, Input, Conv2D, Dense,MaxPooling2D, Dropout, Flatten, UpSampling2D, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNextbatch(batch_size=10, stepNumber=0, imgDim = 128, imageFiles = 'list/of/files', pathSplitIndex = 2, classValLength = 4):\n",
    "    import cv2 as ocr\n",
    "    try:\n",
    "        input_label_list = []\n",
    "        input_data_list = []\n",
    "        counter = 0\n",
    "        start = stepNumber\n",
    "        end = stepNumber + batch_size\n",
    "\n",
    "        for imgF in imageFiles[start:end]:\n",
    "          \n",
    "            input_label_list.append(int(imgF.split('/')[pathSplitIndex][0:classValLength]))\n",
    "            input_data_list.append(ocr.imread(imgF,0))\n",
    "\n",
    "        return (np.array(input_data_list).reshape(-1,imgDim,imgDim,1)\n",
    "                , np.array(input_label_list).astype('int64'))\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        \n",
    "def getData(dataPath='path/To/Data',channels = 0, pathSplitIndex = 2, classValLength = 4, classCount = None, classValue = None):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    imageClass = []\n",
    "    imageFiles = [] \n",
    "    input_label_list = []\n",
    "    input_data_list = []   \n",
    "    selectedFilePaths = []\n",
    "    imageFiles = [dataPath+'/'+f for f in listdir(dataPath) if isfile(join(dataPath, f))]\n",
    "    \n",
    "    for imgF in tqdm(imageFiles, total=len(imageFiles), unit=\"files\"): \n",
    "#         print(imgF)\n",
    "        c = int(imgF.split('/')[pathSplitIndex][0:classValLength])\n",
    "        if( classCount!=None and classValue == None):\n",
    "            imageClass.append(c) \n",
    "            if(len(Counter(imageClass).keys())>classCount):\n",
    "                imageClass[classCount] = imageClass[classCount-1]\n",
    "            else:\n",
    "#                 input_label_list.append(c)\n",
    "#                 input_data_list.append(ocr.imread(imgF,channels))\n",
    "                selectedFilePaths.append(imgF)\n",
    "        elif(classCount==None and classValue!=None):\n",
    "            if(c in classValue):\n",
    "#                 input_label_list.append(c)\n",
    "#                 input_data_list.append(ocr.imread(imgF,channels))\n",
    "                selectedFilePaths.append(imgF)\n",
    "        imageClass = list(set(imageClass))\n",
    "    return np.array(selectedFilePaths)\n",
    "\n",
    "def contrastive_loss(left_model, right_model, y, margin):\n",
    "    with tf.name_scope(\"contrastive-loss\"):\n",
    "        d = tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(left_model,right_model), 2), 1, keep_dims=True))\n",
    "        part1= y * tf.square(d)    \n",
    "        part2 = (1 - y) * tf.square(tf.maximum((margin - d),0))\n",
    "        return tf.reduce_mean(part1 + part2) /2\n",
    "    \n",
    "\n",
    "images_folder_tr = 'images-lfw/'\n",
    "images_folder_val = images_folder_tr\n",
    "def gen_random_train_batch(nb_examples):\n",
    "    out_l,out_r,out_y = [],[],[]\n",
    "    li = random.sample(range(len(df_train)), nb_examples)\n",
    "    for i in li:\n",
    "        im_l = df_train.iloc[i]['name1']+\"/\"+df_train.iloc[i]['name1']+'_'+str(df_train.iloc[i]['im1']).zfill(4)+\".jpg\"\n",
    "        im_r = df_train.iloc[i]['name2']+\"/\"+df_train.iloc[i]['name2']+'_'+str(df_train.iloc[i]['im2']).zfill(4)+\".jpg\"\n",
    "        \n",
    "        \n",
    "        out_l.append(ocr.imread(images_folder_tr+im_l,0))\n",
    "        out_r.append(ocr.imread(images_folder_tr+im_r,0))\n",
    "        out_y.append(df_train.iloc[i]['label'])\n",
    "    out_l = ((np.array(out_l))/255.0).astype('float32')\n",
    "    out_r = ((np.array(out_r))/255.0).astype('float32')\n",
    "    out_y = np.array(out_y).reshape((-1,1))\n",
    "    return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1), np.array(out_y)\n",
    "\n",
    "def gen_random_val_batch(nb_examples):\n",
    "    out_l,out_r,out_y = [],[],[]\n",
    "    li = random.sample(range(len(df_val)), nb_examples)\n",
    "    for i in li:\n",
    "        \n",
    "        im_l = df_val.iloc[i]['name1']+\"/\"+df_val.iloc[i]['name1']+'_'+str(df_val.iloc[i]['im1']).zfill(4)+\".jpg\"\n",
    "        im_r = df_val.iloc[i]['name2']+\"/\"+df_val.iloc[i]['name2']+'_'+str(df_val.iloc[i]['im2']).zfill(4)+\".jpg\"\n",
    "        \n",
    "        \n",
    "        out_l.append(ocr.imread(images_folder_val+im_l,0))\n",
    "        out_r.append(ocr.imread(images_folder_val+im_r,0))\n",
    "        out_y.append(df_val.iloc[i]['label'])\n",
    "    out_l = ((np.array(out_l))/255.0).astype('float32')\n",
    "    out_r = ((np.array(out_r))/255.0).astype('float32')\n",
    "    out_y = np.array(out_y).reshape((-1,1))\n",
    "    return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1), np.array(out_y)\n",
    "\n",
    "# def gen_random_train_batch_sift(nb_examples):\n",
    "#     out_l,out_r,sift_l,sift_r,out_y = [],[],[],[],[]\n",
    "#     li = random.sample(range(len(df_train)), nb_examples)\n",
    "#     for i in li:\n",
    "#         out_l.append(ocr.imread(images_folder_tr+df_train.iloc[i]['left'],0))\n",
    "#         out_r.append(ocr.imread(images_folder_tr+df_train.iloc[i]['right'],0))\n",
    "#         sift_l.append(df_train.iloc[i][3:259])\n",
    "#         sift_r.append(df_train.iloc[i][259:])\n",
    "#         out_y.append(df_train.iloc[i]['label'])\n",
    "#     out_l = ((255.01 - np.array(out_l))/255.0).astype('float32')\n",
    "#     out_r = ((255.01 - np.array(out_r))/255.0).astype('float32')\n",
    "#     sift_l = np.array(sift_l).reshape((-1,256))\n",
    "#     sift_r = np.array(sift_r).reshape((-1,256))\n",
    "#     out_y = np.array(out_y).reshape((-1,1))\n",
    "#     return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1),sift_l,sift_r, out_y\n",
    "\n",
    "# def gen_random_val_batch_sift(nb_examples):\n",
    "#     out_l,out_r,sift_l,sift_r,out_y = [],[],[],[],[]\n",
    "#     li = random.sample(range(len(df_val)), nb_examples)\n",
    "#     for i in li:\n",
    "#         out_l.append(ocr.imread(images_folder_val+df_val.iloc[i]['left'],0))\n",
    "#         out_r.append(ocr.imread(images_folder_val+df_val.iloc[i]['right'],0))\n",
    "#         sift_l.append(df_val.iloc[i][3:259])\n",
    "#         sift_r.append(df_val.iloc[i][259:])\n",
    "#         out_y.append(df_val.iloc[i]['label'])\n",
    "#     out_l = ((255.01 - np.array(out_l))/255.0).astype('float32')\n",
    "#     out_r = ((255.01 - np.array(out_r))/255.0).astype('float32')\n",
    "#     sift_l = np.array(sift_l).reshape((-1,256))\n",
    "#     sift_r = np.array(sift_r).reshape((-1,256))\n",
    "#     out_y = np.array(out_y).reshape((-1,1))\n",
    "#     return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1),sift_l,sift_r, out_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "# def generateDatasetAndSave_Siamese():\n",
    "#     label = []\n",
    "#     left_path = []\n",
    "#     right_path = []\n",
    "#     simCounter = 0\n",
    "#     for l,r in combinations(train_files_list,2):\n",
    "#         if(int(l.split('/')[3][:4]) == int(r.split('/')[3][:4])):\n",
    "#             label.append([1])\n",
    "#     #     else:\n",
    "#     #         label.append([0,1])\n",
    "#             left_path.append(l)\n",
    "#             right_path.append(r)\n",
    "#             simCounter+=1\n",
    "#     diffCounter = 0\n",
    "#     for l,r in combinations(train_files_list,2):\n",
    "#         if(int(l.split('/')[3][:4]) != int(r.split('/')[3][:4])):\n",
    "#             label.append([0])\n",
    "#     #     else:\n",
    "#     #         label.append([0,1])\n",
    "#             left_path.append(l)\n",
    "#             right_path.append(r)\n",
    "#             diffCounter+=1\n",
    "#         if(diffCounter==simCounter):\n",
    "#             break\n",
    "#     df = pd.DataFrame()\n",
    "#     pd.options.display.max_colwidth = 100\n",
    "#     df['left'] = left_path\n",
    "#     df['right'] = right_path\n",
    "#     df['label'] = label\n",
    "#     df.to_csv('dataset_training_siamese.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      (None, 250, 250, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 250, 250, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 62, 62, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 31, 31, 256)       33024     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 15, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "=================================================================\n",
      "Total params: 142,144\n",
      "Trainable params: 142,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "\n",
    "set_session(tf.Session(config=config))\n",
    "imDim = 250\n",
    "input_shape  = (imDim,imDim,1)\n",
    "inp_img = Input(shape = (imDim,imDim,1), name = 'ImageInput')\n",
    "model = inp_img\n",
    "\n",
    "#     model = Input(shape=(imDim,imDim,1))\n",
    "#     model.add(Input(shape = (imDim,imDim,1), name = 'FeatureNet_ImageInput'))\n",
    "model = Conv2D(32,kernel_size=(3, 3),activation='relu',input_shape=input_shape,padding='same')(model)\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model = MaxPooling2D((2,2), padding='valid')(model)\n",
    "model = Conv2D(64, (3, 3), activation='relu',padding='same')(model)\n",
    "#     model.add(Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "model = Dropout(0.3)(model)\n",
    "#     model.add(Conv2D(16, (3, 3), activation='relu',padding='same'))\n",
    "model = Conv2D(128, (3, 3), activation='relu',padding='same')(model)\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "#     model.add(Conv2D(1, (3, 3), activation='relu',padding='same'))\n",
    "#     model.add(Conv2D(2, (3, 3), activation='relu',padding='same'))\n",
    "model = Dropout(0.3)(model)\n",
    "model = Conv2D(256, (1, 1), activation='relu',padding='valid')(model)\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "model = Dropout(0.3)(model)\n",
    "model = Conv2D(64, (1, 1), activation='relu',padding='valid')(model)\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "\n",
    "model = Flatten()(model)\n",
    "\n",
    "# img_in = np.array((-1,imDim,imDim,1), dtype='float32')\n",
    "# img_in = tf.placeholder(shape=(imDim,imDim,1), dtype='float32')\n",
    "\n",
    "feat = Model(inputs=[inp_img], outputs=[model],name = 'Feat_Model')\n",
    "feat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_img = Input(shape = (imDim,imDim,1), name = 'left_img')\n",
    "right_img = Input(shape = (imDim,imDim,1), name = 'right_img')\n",
    "# left_sift = Input(shape= (256,), name = 'left_sift')\n",
    "# right_sift = Input(shape= (256,), name = 'right_sift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Feat_Model/flatten_1/Reshape:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "left_feats = feat(left_img)\n",
    "right_feats = feat(right_img)\n",
    "\n",
    "# inpTensor = Input((1,256,), name = 'SIFTInput')\n",
    "# finalOut = Flatten()(inpTensor)  \n",
    "# sift_model = Model(inputs=[inpTensor], outputs=[finalOut], name='Sift_Model')\n",
    "# sift_model.summary()\n",
    "\n",
    "# left_sift_feats = sift_model(left_sift)\n",
    "# right_sift_feats = sift_model(right_sift)\n",
    "# print(left_sift_feats)\n",
    "print(left_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import concatenate #, subtract, multiply, division\n",
    "from keras.utils import to_categorical\n",
    "import random  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "left_img (InputLayer)            (None, 250, 250, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "right_img (InputLayer)           (None, 250, 250, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Feat_Model (Model)               (None, 3136)          142144      left_img[0][0]                   \n",
      "                                                                   right_img[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merged_feats (Concatenate)       (None, 6272)          0           Feat_Model[1][0]                 \n",
      "                                                                   Feat_Model[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          6423552     merged_feats[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 1024)          4096        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 1024)          0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 1024)          0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4)             4100        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 4)             16          dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 4)             0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 4)             0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2)             10          dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 6,573,918\n",
      "Trainable params: 6,571,862\n",
      "Non-trainable params: 2,056\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## CNN+SIFT\n",
    "# merged_feats = concatenate([left_feats, right_feats, left_sift_feats, right_sift_feats], name = 'merged_feats')\n",
    "## Only SIFT merge\n",
    "# merged_feats = concatenate([left_sift_feats, right_sift_feats], name = 'merged_feats')\n",
    "## Only CNN merge\n",
    "merged_feats = concatenate([left_feats, right_feats], name = 'merged_feats')\n",
    "merged_feats = Dense(1024, activation = 'linear')(merged_feats)\n",
    "merged_feats = BatchNormalization()(merged_feats)\n",
    "merged_feats = Activation('relu')(merged_feats)\n",
    "merged_feats = Dropout(0.3)(merged_feats)\n",
    "merged_feats = Dense(4, activation = 'linear')(merged_feats)\n",
    "merged_feats = BatchNormalization()(merged_feats)\n",
    "merged_feats = Activation('relu')(merged_feats)\n",
    "merged_feats = Dropout(0.3)(merged_feats)\n",
    "merged_feats = Dense(2, activation = 'softmax')(merged_feats)\n",
    "## only sift\n",
    "# similarity_model = Model(inputs = [left_sift,right_sift], outputs = [merged_feats], name = 'Similarity_Model')\n",
    "## only cnn\n",
    "similarity_model = Model(inputs = [left_img, right_img], outputs = [merged_feats], name = 'Similarity_Model')\n",
    "## with cnn+sift\n",
    "# similarity_model = Model(inputs = [left_img, right_img, left_sift,right_sift], outputs = [merged_feats], name = 'Similarity_Model')\n",
    "similarity_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_folder = ''\n",
    "sgd = K.optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "similarity_model.compile(optimizer=sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# similarity_model.load_weights('weights/weights-siamese-AND-concat-cnn-0.377613.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = 'pairsDevTrain.csv'\n",
    "val_set = 'pairsDevTest.csv'\n",
    "df_train = pd.DataFrame.from_csv(train_set).reset_index()\n",
    "df_val = pd.DataFrame.from_csv(val_set).reset_index()\n",
    "df_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iteration = 0\n",
    "# left_image = ocr.imread(df.iloc[iteration]['left'],0)\n",
    "# right_image = ocr.imread(df.iloc[iteration]['right'],0)\n",
    "# y = df.iloc[iteration]['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on: 2200, Validate on: 1000\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,31,31,128]\n\t [[Node: Feat_Model/max_pooling2d_3/MaxPool = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Feat_Model/conv2d_3/Relu)]]\n\t [[Node: Mean_3/_99 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2601_Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Feat_Model/max_pooling2d_3/MaxPool', defined at:\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-d41c2145aeab>\", line 1, in <module>\n    left_feats = feat(left_img)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 596, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 2061, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 2212, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\pooling.py\", line 154, in call\n    data_format=self.data_format)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\pooling.py\", line 217, in _pooling_function\n    pool_mode='max')\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3288, in pool2d\n    x = tf.nn.max_pool(x, pool_size, strides, padding=padding)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1769, in max_pool\n    name=name)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1605, in _max_pool\n    data_format=data_format, name=name)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,31,31,128]\n\t [[Node: Feat_Model/max_pooling2d_3/MaxPool = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Feat_Model/conv2d_3/Relu)]]\n\t [[Node: Mean_3/_99 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2601_Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,31,31,128]\n\t [[Node: Feat_Model/max_pooling2d_3/MaxPool = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Feat_Model/conv2d_3/Relu)]]\n\t [[Node: Mean_3/_99 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2601_Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-eee8b6e38965>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m#         batch_metrics = similarity_model.train_on_batch([left_image,right_image,sift_l,sift_r],[y])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m#         batch_metrics = similarity_model.train_on_batch([sift_l,sift_r],[y])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mbatch_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilarity_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mleft_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright_image\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mbatch_metric_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1640\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1642\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2269\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2270\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,31,31,128]\n\t [[Node: Feat_Model/max_pooling2d_3/MaxPool = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Feat_Model/conv2d_3/Relu)]]\n\t [[Node: Mean_3/_99 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2601_Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Feat_Model/max_pooling2d_3/MaxPool', defined at:\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-d41c2145aeab>\", line 1, in <module>\n    left_feats = feat(left_img)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 596, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 2061, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\topology.py\", line 2212, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\pooling.py\", line 154, in call\n    data_format=self.data_format)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\pooling.py\", line 217, in _pooling_function\n    pool_mode='max')\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3288, in pool2d\n    x = tf.nn.max_pool(x, pool_size, strides, padding=padding)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1769, in max_pool\n    name=name)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1605, in _max_pool\n    data_format=data_format, name=name)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Jyoti Kini\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,31,31,128]\n\t [[Node: Feat_Model/max_pooling2d_3/MaxPool = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Feat_Model/conv2d_3/Relu)]]\n\t [[Node: Mean_3/_99 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2601_Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 64\n",
    "imgDim =  250\n",
    "best_loss_tr = np.infty\n",
    "train_files_list = df_train.shape[0]\n",
    "train_num_examples = train_files_list\n",
    "print('Train on: %2d, Validate on: %2d' %(train_num_examples, df_val.shape[0]))\n",
    "n_iterations_per_epoch = train_num_examples // batch_size\n",
    "# n_iterations_validation = val_num_examples // batch_size\n",
    "# Set's how much noise we're adding to the MNIST images\n",
    "noise_factor = 0.0\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tr_loss_vals = []\n",
    "tr_acc_vals = []\n",
    "val_acc_vals = []\n",
    "v_batch_size = df_val.shape[0]\n",
    "early_stopping_counter = 0\n",
    "patience = 5\n",
    "max_val_acc = 0\n",
    "\n",
    "batch_metrics = None\n",
    "batch_metric_loss = []\n",
    "batch_metric_acc = []\n",
    "for epoch in range(n_epochs):\n",
    "    for iteration in range(int(train_files_list/batch_size)):        \n",
    "        left_image, right_image, y = gen_random_train_batch(batch_size)\n",
    "        y = to_categorical(y)\n",
    "#         print('\\n------\\n'+str(y)+'\\n------\\n')\n",
    "        left_image = left_image.reshape((-1, imgDim, imgDim, 1))\n",
    "        right_image = right_image.reshape((-1, imgDim, imgDim, 1))\n",
    "#         batch_metrics = similarity_model.train_on_batch([left_image,right_image,sift_l,sift_r],[y])\n",
    "#         batch_metrics = similarity_model.train_on_batch([sift_l,sift_r],[y])\n",
    "        batch_metrics = similarity_model.train_on_batch([left_image,right_image],[y])\n",
    "        \n",
    "        batch_metric_loss.append(batch_metrics[0])\n",
    "        batch_metric_acc.append(batch_metrics[1])\n",
    "        print(\"\\rTraining the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_per_epoch,\n",
    "                  iteration * 100 / n_iterations_per_epoch),\n",
    "              end=\"\" * 10)\n",
    "    loss_tr = np.mean(batch_metric_loss)\n",
    "    acc_tr = np.mean(batch_metric_acc)\n",
    "    tr_loss_vals.append(loss_tr)\n",
    "    tr_acc_vals.append(acc_tr)\n",
    "    \n",
    "    v_left_image ,v_right_image, v_y = gen_random_val_batch(v_batch_size)\n",
    "    \n",
    "#     pred_sim = similarity_model.predict([v_left_image ,v_right_image,v_sift_l, v_sift_r])\n",
    "#     pred_sim = similarity_model.predict([v_sift_l, v_sift_r])\n",
    "    pred_sim = similarity_model.predict([v_left_image ,v_right_image])\n",
    "    pred_val_sim = []\n",
    "    for p in pred_sim:\n",
    "        pred_val_sim.append(np.argmax(p))\n",
    "    v_acc = float((np.array(pred_val_sim).reshape((v_batch_size,1))==v_y).sum())/float(len(v_y))\n",
    "    val_acc_vals.append(v_acc)\n",
    "    \n",
    "    print(\"\\rEpoch: {}  Train accuracy: {:.4f}%, Validation acc: {:.4f}%, Loss: {:.6f}{}\".format(\n",
    "        epoch + 1, (acc_tr) * 100, (v_acc)*100.0, loss_tr,\n",
    "        \" (improved)\" if loss_tr < best_loss_tr else \"\"))\n",
    "    if loss_tr < best_loss_tr and ((epoch % 1)==0):\n",
    "#             save_path = saver.save(sess, checkpoint_path)\n",
    "        best_loss_tr = loss_tr\n",
    "        filepath='weights/siam-cnn-concat-[val-acc-'+str(v_acc)+'].hdf5'\n",
    "        similarity_model.save(filepath)\n",
    "    if max_val_acc < v_acc:\n",
    "        max_val_acc = v_acc\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter+=1\n",
    "    if early_stopping_counter==patience:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame()\n",
    "df_metrics['accuracy'] = tr_acc_vals\n",
    "df_metrics['loss'] = tr_loss_vals\n",
    "df_metrics['val_acc'] = val_acc_vals\n",
    "df_metrics.to_csv('plots/siam-cnn-concat-metric-cnn.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = df_metrics.plot()\n",
    "fig = ax.figure\n",
    "fig.savefig('plots/siam-cnn-concat-plot-cnn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# similarity_model = load model (best one)\n",
    "%matplotlib inline\n",
    "def show_model_output(nb_examples = 5):\n",
    "    \n",
    "#     pv_a, pv_b,pv_s_l,pv_s_r, pv_sim = gen_random_val_batch(nb_examples)\n",
    "    pv_a, pv_b, pv_sim = gen_random_val_batch(nb_examples)\n",
    "#     pred_sim = similarity_model.predict([pv_a, pv_b,pv_s_l,pv_s_r])\n",
    "    pred_sim = similarity_model.predict([pv_a, pv_b])\n",
    "    p_val_argmax=[]\n",
    "    print(pred_sim)\n",
    "    for p in pred_sim:\n",
    "        p_val_argmax.append(np.argmax(p))\n",
    "    p_val_argmax = np.array(p_val_argmax)\n",
    "    fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))\n",
    "    for c_a, c_b, c_d, p_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, pred_sim, m_axs.T):\n",
    "        ax1.imshow(c_a[:,:,0])\n",
    "        ax1.set_title('Left Image\\n Actual Label: %3.0f%%' % (100*c_d))\n",
    "        ax1.axis('off')\n",
    "        ax2.imshow(c_b[:,:,0])\n",
    "        ax2.set_title('Right Image\\n Different %3.0f%% \\nSame %3.0f%% ' % (100*p_d[0],100*p_d[1]))\n",
    "        ax2.axis('off')\n",
    "    return fig\n",
    "# a completely untrained model\n",
    "_ = show_model_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_left_image ,v_right_image, v_y = gen_random_val_batch(100)\n",
    "pred_sim = similarity_model.predict([v_left_image ,v_right_image])\n",
    "(pred_sim.round().astype('int')==v_y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l,r,y = gen_random_train_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.sample(range(1, 10), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d201dfe8dca7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(feat, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(similarity_model, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1,1,1,1,1,1,1,1,0])\n",
    "b = np.array([1,1,1,1,1,1,1,1,0,0])\n",
    "(a==b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l,r,s,y = gen_random_val_batch_sift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      (None, 250, 250, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 250, 250, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 62, 62, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 31, 31, 256)       33024     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 15, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "=================================================================\n",
      "Total params: 142,144\n",
      "Trainable params: 142,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow-gpu]",
   "language": "python",
   "name": "Python [tensorflow-gpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
