{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2 as ocr\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import shutil\n",
    "from tqdm import tqdm,trange\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "from numpy.random import choice\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation,BatchNormalization,Lambda, Input, Conv2D, Dense,MaxPooling2D, Dropout, Flatten, UpSampling2D, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNextbatch(batch_size=10, stepNumber=0, imgDim = 128, imageFiles = 'list/of/files', pathSplitIndex = 2, classValLength = 4):\n",
    "    import cv2 as ocr\n",
    "    try:\n",
    "        input_label_list = []\n",
    "        input_data_list = []\n",
    "        counter = 0\n",
    "        start = stepNumber\n",
    "        end = stepNumber + batch_size\n",
    "\n",
    "        for imgF in imageFiles[start:end]:\n",
    "          \n",
    "            input_label_list.append(int(imgF.split('/')[pathSplitIndex][0:classValLength]))\n",
    "            input_data_list.append(ocr.imread(imgF,0))\n",
    "\n",
    "        return (np.array(input_data_list).reshape(-1,imgDim,imgDim,1)\n",
    "                , np.array(input_label_list).astype('int64'))\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        \n",
    "def getData(dataPath='path/To/Data',channels = 0, pathSplitIndex = 2, classValLength = 4, classCount = None, classValue = None):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    imageClass = []\n",
    "    imageFiles = [] \n",
    "    input_label_list = []\n",
    "    input_data_list = []   \n",
    "    selectedFilePaths = []\n",
    "    imageFiles = [dataPath+'/'+f for f in listdir(dataPath) if isfile(join(dataPath, f))]\n",
    "    \n",
    "    for imgF in tqdm(imageFiles, total=len(imageFiles), unit=\"files\"): \n",
    "#         print(imgF)\n",
    "        c = int(imgF.split('/')[pathSplitIndex][0:classValLength])\n",
    "        if( classCount!=None and classValue == None):\n",
    "            imageClass.append(c) \n",
    "            if(len(Counter(imageClass).keys())>classCount):\n",
    "                imageClass[classCount] = imageClass[classCount-1]\n",
    "            else:\n",
    "#                 input_label_list.append(c)\n",
    "#                 input_data_list.append(ocr.imread(imgF,channels))\n",
    "                selectedFilePaths.append(imgF)\n",
    "        elif(classCount==None and classValue!=None):\n",
    "            if(c in classValue):\n",
    "#                 input_label_list.append(c)\n",
    "#                 input_data_list.append(ocr.imread(imgF,channels))\n",
    "                selectedFilePaths.append(imgF)\n",
    "        imageClass = list(set(imageClass))\n",
    "    return np.array(selectedFilePaths)\n",
    "\n",
    "def contrastive_loss(left_model, right_model, y, margin):\n",
    "    with tf.name_scope(\"contrastive-loss\"):\n",
    "        d = tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(left_model,right_model), 2), 1, keep_dims=True))\n",
    "        part1= y * tf.square(d)    \n",
    "        part2 = (1 - y) * tf.square(tf.maximum((margin - d),0))\n",
    "        return tf.reduce_mean(part1 + part2) /2\n",
    "    \n",
    "\n",
    "images_folder_tr = 'images-lfw/'\n",
    "images_folder_val = images_folder_tr\n",
    "def gen_random_train_batch(nb_examples):\n",
    "    out_l,out_r,out_y = [],[],[]\n",
    "    li = random.sample(range(len(df_train)), nb_examples)\n",
    "    for i in li:\n",
    "        im_l = df_train.iloc[i]['name1']+\"/\"+df_train.iloc[i]['name1']+'_'+str(df_train.iloc[i]['im1']).zfill(4)+\".jpg\"\n",
    "        im_r = df_train.iloc[i]['name2']+\"/\"+df_train.iloc[i]['name2']+'_'+str(df_train.iloc[i]['im2']).zfill(4)+\".jpg\"\n",
    "        \n",
    "        \n",
    "        out_l.append(ocr.imread(images_folder_tr+im_l,0))\n",
    "        out_r.append(ocr.imread(images_folder_tr+im_r,0))\n",
    "        out_y.append(df_train.iloc[i]['label'])\n",
    "    out_l = ((np.array(out_l))/255.0).astype('float32')\n",
    "    out_r = ((np.array(out_r))/255.0).astype('float32')\n",
    "    out_y = np.array(out_y).reshape((-1,1))\n",
    "    return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1), np.array(out_y)\n",
    "\n",
    "def gen_random_val_batch(nb_examples):\n",
    "    out_l,out_r,out_y = [],[],[]\n",
    "    li = random.sample(range(len(df_val)), nb_examples)\n",
    "    for i in li:\n",
    "        \n",
    "        im_l = df_val.iloc[i]['name1']+\"/\"+df_val.iloc[i]['name1']+'_'+str(df_val.iloc[i]['im1']).zfill(4)+\".jpg\"\n",
    "        im_r = df_val.iloc[i]['name2']+\"/\"+df_val.iloc[i]['name2']+'_'+str(df_val.iloc[i]['im2']).zfill(4)+\".jpg\"\n",
    "        \n",
    "        \n",
    "        out_l.append(ocr.imread(images_folder_val+im_l,0))\n",
    "        out_r.append(ocr.imread(images_folder_val+im_r,0))\n",
    "        out_y.append(df_val.iloc[i]['label'])\n",
    "    out_l = ((np.array(out_l))/255.0).astype('float32')\n",
    "    out_r = ((np.array(out_r))/255.0).astype('float32')\n",
    "    out_y = np.array(out_y).reshape((-1,1))\n",
    "    return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1), np.array(out_y)\n",
    "\n",
    "# def gen_random_train_batch_sift(nb_examples):\n",
    "#     out_l,out_r,sift_l,sift_r,out_y = [],[],[],[],[]\n",
    "#     li = random.sample(range(len(df_train)), nb_examples)\n",
    "#     for i in li:\n",
    "#         out_l.append(ocr.imread(images_folder_tr+df_train.iloc[i]['left'],0))\n",
    "#         out_r.append(ocr.imread(images_folder_tr+df_train.iloc[i]['right'],0))\n",
    "#         sift_l.append(df_train.iloc[i][3:259])\n",
    "#         sift_r.append(df_train.iloc[i][259:])\n",
    "#         out_y.append(df_train.iloc[i]['label'])\n",
    "#     out_l = ((255.01 - np.array(out_l))/255.0).astype('float32')\n",
    "#     out_r = ((255.01 - np.array(out_r))/255.0).astype('float32')\n",
    "#     sift_l = np.array(sift_l).reshape((-1,256))\n",
    "#     sift_r = np.array(sift_r).reshape((-1,256))\n",
    "#     out_y = np.array(out_y).reshape((-1,1))\n",
    "#     return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1),sift_l,sift_r, out_y\n",
    "\n",
    "# def gen_random_val_batch_sift(nb_examples):\n",
    "#     out_l,out_r,sift_l,sift_r,out_y = [],[],[],[],[]\n",
    "#     li = random.sample(range(len(df_val)), nb_examples)\n",
    "#     for i in li:\n",
    "#         out_l.append(ocr.imread(images_folder_val+df_val.iloc[i]['left'],0))\n",
    "#         out_r.append(ocr.imread(images_folder_val+df_val.iloc[i]['right'],0))\n",
    "#         sift_l.append(df_val.iloc[i][3:259])\n",
    "#         sift_r.append(df_val.iloc[i][259:])\n",
    "#         out_y.append(df_val.iloc[i]['label'])\n",
    "#     out_l = ((255.01 - np.array(out_l))/255.0).astype('float32')\n",
    "#     out_r = ((255.01 - np.array(out_r))/255.0).astype('float32')\n",
    "#     sift_l = np.array(sift_l).reshape((-1,256))\n",
    "#     sift_r = np.array(sift_r).reshape((-1,256))\n",
    "#     out_y = np.array(out_y).reshape((-1,1))\n",
    "#     return out_l.reshape(-1,imDim,imDim,1), out_r.reshape(-1,imDim,imDim,1),sift_l,sift_r, out_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "# def generateDatasetAndSave_Siamese():\n",
    "#     label = []\n",
    "#     left_path = []\n",
    "#     right_path = []\n",
    "#     simCounter = 0\n",
    "#     for l,r in combinations(train_files_list,2):\n",
    "#         if(int(l.split('/')[3][:4]) == int(r.split('/')[3][:4])):\n",
    "#             label.append([1])\n",
    "#     #     else:\n",
    "#     #         label.append([0,1])\n",
    "#             left_path.append(l)\n",
    "#             right_path.append(r)\n",
    "#             simCounter+=1\n",
    "#     diffCounter = 0\n",
    "#     for l,r in combinations(train_files_list,2):\n",
    "#         if(int(l.split('/')[3][:4]) != int(r.split('/')[3][:4])):\n",
    "#             label.append([0])\n",
    "#     #     else:\n",
    "#     #         label.append([0,1])\n",
    "#             left_path.append(l)\n",
    "#             right_path.append(r)\n",
    "#             diffCounter+=1\n",
    "#         if(diffCounter==simCounter):\n",
    "#             break\n",
    "#     df = pd.DataFrame()\n",
    "#     pd.options.display.max_colwidth = 100\n",
    "#     df['left'] = left_path\n",
    "#     df['right'] = right_path\n",
    "#     df['label'] = label\n",
    "#     df.to_csv('dataset_training_siamese.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      (None, 250, 250, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 250, 250, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 62, 62, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 31, 31, 256)       33024     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 15, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "=================================================================\n",
      "Total params: 142,144\n",
      "Trainable params: 142,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "\n",
    "set_session(tf.Session(config=config))\n",
    "imDim = 250\n",
    "input_shape  = (imDim,imDim,1)\n",
    "inp_img = Input(shape = (imDim,imDim,1), name = 'ImageInput')\n",
    "model = inp_img\n",
    "\n",
    "#     model = Input(shape=(imDim,imDim,1))\n",
    "#     model.add(Input(shape = (imDim,imDim,1), name = 'FeatureNet_ImageInput'))\n",
    "model = Conv2D(32,kernel_size=(3, 3),activation='relu',input_shape=input_shape,padding='same')(model)\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model = MaxPooling2D((2,2), padding='valid')(model)\n",
    "model = Conv2D(64, (3, 3), activation='relu',padding='same')(model)\n",
    "#     model.add(Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "model = Dropout(0.3)(model)\n",
    "#     model.add(Conv2D(16, (3, 3), activation='relu',padding='same'))\n",
    "model = Conv2D(128, (3, 3), activation='relu',padding='same')(model)\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "#     model.add(Conv2D(1, (3, 3), activation='relu',padding='same'))\n",
    "#     model.add(Conv2D(2, (3, 3), activation='relu',padding='same'))\n",
    "model = Dropout(0.3)(model)\n",
    "model = Conv2D(256, (1, 1), activation='relu',padding='valid')(model)\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "model = Dropout(0.3)(model)\n",
    "model = Conv2D(64, (1, 1), activation='relu',padding='valid')(model)\n",
    "model = MaxPooling2D((2,2),padding='valid')(model)\n",
    "\n",
    "model = Flatten()(model)\n",
    "\n",
    "# img_in = np.array((-1,imDim,imDim,1), dtype='float32')\n",
    "# img_in = tf.placeholder(shape=(imDim,imDim,1), dtype='float32')\n",
    "\n",
    "feat = Model(inputs=[inp_img], outputs=[model],name = 'Feat_Model')\n",
    "feat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_img = Input(shape = (imDim,imDim,1), name = 'left_img')\n",
    "right_img = Input(shape = (imDim,imDim,1), name = 'right_img')\n",
    "# left_sift = Input(shape= (256,), name = 'left_sift')\n",
    "# right_sift = Input(shape= (256,), name = 'right_sift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Feat_Model/flatten_1/Reshape:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "left_feats = feat(left_img)\n",
    "right_feats = feat(right_img)\n",
    "\n",
    "# inpTensor = Input((1,256,), name = 'SIFTInput')\n",
    "# finalOut = Flatten()(inpTensor)  \n",
    "# sift_model = Model(inputs=[inpTensor], outputs=[finalOut], name='Sift_Model')\n",
    "# sift_model.summary()\n",
    "\n",
    "# left_sift_feats = sift_model(left_sift)\n",
    "# right_sift_feats = sift_model(right_sift)\n",
    "# print(left_sift_feats)\n",
    "print(left_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate #, subtract, multiply, division\n",
    "from keras.utils import to_categorical\n",
    "import random  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_img (InputLayer)           (None, 250, 250, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "right_img (InputLayer)          (None, 250, 250, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Feat_Model (Model)              (None, 3136)         142144      left_img[0][0]                   \n",
      "                                                                 right_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merged_feats (Concatenate)      (None, 6272)         0           Feat_Model[1][0]                 \n",
      "                                                                 Feat_Model[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         6423552     merged_feats[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1024)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            4100        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4)            16          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4)            0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4)            0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            10          dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,573,918\n",
      "Trainable params: 6,571,862\n",
      "Non-trainable params: 2,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## CNN+SIFT\n",
    "# merged_feats = concatenate([left_feats, right_feats, left_sift_feats, right_sift_feats], name = 'merged_feats')\n",
    "## Only SIFT merge\n",
    "# merged_feats = concatenate([left_sift_feats, right_sift_feats], name = 'merged_feats')\n",
    "## Only CNN merge\n",
    "merged_feats = concatenate([left_feats, right_feats], name = 'merged_feats')\n",
    "merged_feats = Dense(1024, activation = 'linear')(merged_feats)\n",
    "merged_feats = BatchNormalization()(merged_feats)\n",
    "merged_feats = Activation('relu')(merged_feats)\n",
    "merged_feats = Dropout(0.3)(merged_feats)\n",
    "merged_feats = Dense(4, activation = 'linear')(merged_feats)\n",
    "merged_feats = BatchNormalization()(merged_feats)\n",
    "merged_feats = Activation('relu')(merged_feats)\n",
    "merged_feats = Dropout(0.3)(merged_feats)\n",
    "merged_feats = Dense(2, activation = 'softmax')(merged_feats)\n",
    "## only sift\n",
    "# similarity_model = Model(inputs = [left_sift,right_sift], outputs = [merged_feats], name = 'Similarity_Model')\n",
    "## only cnn\n",
    "similarity_model = Model(inputs = [left_img, right_img], outputs = [merged_feats], name = 'Similarity_Model')\n",
    "## with cnn+sift\n",
    "# similarity_model = Model(inputs = [left_img, right_img, left_sift,right_sift], outputs = [merged_feats], name = 'Similarity_Model')\n",
    "similarity_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_folder = ''\n",
    "sgd = K.optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "similarity_model.compile(optimizer=sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# similarity_model.load_weights('weights/weights-siamese-AND-concat-cnn-0.377613.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = 'pairsDevTrain.csv'\n",
    "val_set = 'pairsDevTest.csv'\n",
    "df_train = pd.DataFrame.from_csv(train_set).reset_index()\n",
    "df_val = pd.DataFrame.from_csv(val_set).reset_index()\n",
    "df_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iteration = 0\n",
    "# left_image = ocr.imread(df.iloc[iteration]['left'],0)\n",
    "# right_image = ocr.imread(df.iloc[iteration]['right'],0)\n",
    "# y = df.iloc[iteration]['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on: 2200, Validate on: 1000\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 64\n",
    "imgDim =  250\n",
    "best_loss_tr = np.infty\n",
    "train_files_list = df_train.shape[0]\n",
    "train_num_examples = train_files_list\n",
    "print('Train on: %2d, Validate on: %2d' %(train_num_examples, df_val.shape[0]))\n",
    "n_iterations_per_epoch = train_num_examples // batch_size\n",
    "# n_iterations_validation = val_num_examples // batch_size\n",
    "# Set's how much noise we're adding to the MNIST images\n",
    "noise_factor = 0.0\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tr_loss_vals = []\n",
    "tr_acc_vals = []\n",
    "val_acc_vals = []\n",
    "v_batch_size = df_val.shape[0]\n",
    "early_stopping_counter = 0\n",
    "patience = 5\n",
    "max_val_acc = 0\n",
    "\n",
    "batch_metrics = None\n",
    "batch_metric_loss = []\n",
    "batch_metric_acc = []\n",
    "for epoch in range(n_epochs):\n",
    "    for iteration in range(int(train_files_list/batch_size)):        \n",
    "        left_image, right_image, y = gen_random_train_batch(batch_size)\n",
    "        y = to_categorical(y)\n",
    "#         print('\\n------\\n'+str(y)+'\\n------\\n')\n",
    "        left_image = left_image.reshape((-1, imgDim, imgDim, 1))\n",
    "        right_image = right_image.reshape((-1, imgDim, imgDim, 1))\n",
    "#         batch_metrics = similarity_model.train_on_batch([left_image,right_image,sift_l,sift_r],[y])\n",
    "#         batch_metrics = similarity_model.train_on_batch([sift_l,sift_r],[y])\n",
    "        batch_metrics = similarity_model.train_on_batch([left_image,right_image],[y])\n",
    "        \n",
    "        batch_metric_loss.append(batch_metrics[0])\n",
    "        batch_metric_acc.append(batch_metrics[1])\n",
    "        print(\"\\rTraining the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_per_epoch,\n",
    "                  iteration * 100 / n_iterations_per_epoch),\n",
    "              end=\"\" * 10)\n",
    "    loss_tr = np.mean(batch_metric_loss)\n",
    "    acc_tr = np.mean(batch_metric_acc)\n",
    "    tr_loss_vals.append(loss_tr)\n",
    "    tr_acc_vals.append(acc_tr)\n",
    "    \n",
    "    v_left_image ,v_right_image, v_y = gen_random_val_batch(v_batch_size)\n",
    "    \n",
    "#     pred_sim = similarity_model.predict([v_left_image ,v_right_image,v_sift_l, v_sift_r])\n",
    "#     pred_sim = similarity_model.predict([v_sift_l, v_sift_r])\n",
    "    pred_sim = similarity_model.predict([v_left_image ,v_right_image])\n",
    "    pred_val_sim = []\n",
    "    for p in pred_sim:\n",
    "        pred_val_sim.append(np.argmax(p))\n",
    "    v_acc = float((np.array(pred_val_sim).reshape((v_batch_size,1))==v_y).sum())/float(len(v_y))\n",
    "    val_acc_vals.append(v_acc)\n",
    "    \n",
    "    print(\"\\rEpoch: {}  Train accuracy: {:.4f}%, Validation acc: {:.4f}%, Loss: {:.6f}{}\".format(\n",
    "        epoch + 1, (acc_tr) * 100, (v_acc)*100.0, loss_tr,\n",
    "        \" (improved)\" if loss_tr < best_loss_tr else \"\"))\n",
    "    if loss_tr < best_loss_tr and ((epoch % 1)==0):\n",
    "#             save_path = saver.save(sess, checkpoint_path)\n",
    "        best_loss_tr = loss_tr\n",
    "        filepath='weights/siam-cnn-concat-[val-acc-'+str(v_acc)+'].hdf5'\n",
    "        similarity_model.save(filepath)\n",
    "    if max_val_acc < v_acc:\n",
    "        max_val_acc = v_acc\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter+=1\n",
    "    if early_stopping_counter==patience:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame()\n",
    "df_metrics['accuracy'] = tr_acc_vals\n",
    "df_metrics['loss'] = tr_loss_vals\n",
    "df_metrics['val_acc'] = val_acc_vals\n",
    "df_metrics.to_csv('plots/siam-cnn-concat-metric-cnn.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = df_metrics.plot()\n",
    "fig = ax.figure\n",
    "fig.savefig('plots/siam-cnn-concat-plot-cnn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# similarity_model = load model (best one)\n",
    "%matplotlib inline\n",
    "def show_model_output(nb_examples = 5):\n",
    "    \n",
    "#     pv_a, pv_b,pv_s_l,pv_s_r, pv_sim = gen_random_val_batch(nb_examples)\n",
    "    pv_a, pv_b, pv_sim = gen_random_val_batch(nb_examples)\n",
    "#     pred_sim = similarity_model.predict([pv_a, pv_b,pv_s_l,pv_s_r])\n",
    "    pred_sim = similarity_model.predict([pv_a, pv_b])\n",
    "    p_val_argmax=[]\n",
    "    print(pred_sim)\n",
    "    for p in pred_sim:\n",
    "        p_val_argmax.append(np.argmax(p))\n",
    "    p_val_argmax = np.array(p_val_argmax)\n",
    "    fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))\n",
    "    for c_a, c_b, c_d, p_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, pred_sim, m_axs.T):\n",
    "        ax1.imshow(c_a[:,:,0])\n",
    "        ax1.set_title('Left Image\\n Actual Label: %3.0f%%' % (100*c_d))\n",
    "        ax1.axis('off')\n",
    "        ax2.imshow(c_b[:,:,0])\n",
    "        ax2.set_title('Right Image\\n Different %3.0f%% \\nSame %3.0f%% ' % (100*p_d[0],100*p_d[1]))\n",
    "        ax2.axis('off')\n",
    "    return fig\n",
    "# a completely untrained model\n",
    "_ = show_model_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_left_image ,v_right_image, v_y = gen_random_val_batch(100)\n",
    "pred_sim = similarity_model.predict([v_left_image ,v_right_image])\n",
    "(pred_sim.round().astype('int')==v_y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,r,y = gen_random_train_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.sample(range(1, 10), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(feat, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(similarity_model, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1,1,1,1,1,1,1,1,0])\n",
    "b = np.array([1,1,1,1,1,1,1,1,0,0])\n",
    "(a==b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l,r,s,y = gen_random_val_batch_sift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
